diff -ruN 4_9_337_orig/drivers/block/zram/Kconfig 4_9_337_zram_entropy/drivers/block/zram/Kconfig
--- 4_9_337_orig/drivers/block/zram/Kconfig	2023-11-13 12:38:11.190267223 +0800
+++ 4_9_337_zram_entropy/drivers/block/zram/Kconfig	2023-11-13 18:47:21.553325093 +0800
@@ -42,3 +42,20 @@
 config ZRAM_DEFAULT_COMP_ALGORITHM
 	string "Default ZRAM algorithm"
 	default "lz4"
+
+config ZRAM_ENTROPY
+	bool "Use entropy optimization for zram"
+	depends on ZRAM
+	help
+	  With this feature, entropy will be calculated for each page.
+	  Pages above ZRAM_ENTROPY_THRESHOLD entropy will be
+	  stored uncompressed. Use this feature if you need a performance
+	  boost and a small loss in compression.
+
+config ZRAM_ENTROPY_THRESHOLD
+	int
+	depends on ZRAM && ZRAM_ENTROPY
+	default 100000
+	help
+	  Pages with entropy above ZRAM_ENTROPY_THRESHOLD will be stored
+	  uncompressed. The default value was chosen as a 
diff -ruN 4_9_337_orig/drivers/block/zram/zram_drv.c 4_9_337_zram_entropy/drivers/block/zram/zram_drv.c
--- 4_9_337_orig/drivers/block/zram/zram_drv.c	2023-11-13 12:38:11.190267223 +0800
+++ 4_9_337_zram_entropy/drivers/block/zram/zram_drv.c	2023-11-13 19:51:55.499111680 +0800
@@ -54,6 +54,9 @@
 static int zram_bvec_read(struct zram *zram, struct bio_vec *bvec,
 				u32 index, int offset, struct bio *bio);
 
+#ifdef CONFIG_ZRAM_ENTROPY
+unsigned long sysctl_zram_entropy_threshold __read_mostly = CONFIG_ZRAM_ENTROPY_THRESHOLD;
+#endif
 
 static int zram_slot_trylock(struct zram *zram, u32 index)
 {
@@ -1334,6 +1337,34 @@
 	return ret;
 }
 
+#ifdef CONFIG_ZRAM_ENTROPY
+static inline u32 ilog2_w(u64 n)
+{
+	return ilog2(n * n * n * n);
+}
+
+static inline s32 shannon_entropy(const u8 *src)
+{
+	s32 entropy_sum = 0;
+	u32 sz_base, i;
+	u16 entropy_count[256] = { 0 };
+
+	for (i = 0; i < PAGE_SIZE; ++i)
+		entropy_count[src[i]]++;
+
+	sz_base = ilog2_w(PAGE_SIZE);
+	for (i = 0; i < ARRAY_SIZE(entropy_count); ++i) {
+		if (entropy_count[i] > 0) {
+			s32 p = entropy_count[i];
+
+			entropy_sum += p * (sz_base - ilog2_w((u64)p));
+		}
+	}
+
+	return entropy_sum;
+}
+#endif
+
 static int __zram_bvec_write(struct zram *zram, struct bio_vec *bvec,
 				u32 index, struct bio *bio)
 {
@@ -1360,7 +1391,17 @@
 compress_again:
 	zstrm = zcomp_stream_get(zram->comp);
 	src = kmap_atomic(page);
+
+#ifdef CONFIG_ZRAM_ENTROPY
+	/* Just save this page uncompressible */
+	if (shannon_entropy((const u8 *)src) > sysctl_zram_entropy_threshold)
+		comp_len = PAGE_SIZE;
+	else
+		ret = zcomp_compress(zstrm, src, &comp_len);
+#else
 	ret = zcomp_compress(zstrm, src, &comp_len);
+#endif
+
 	kunmap_atomic(src);
 
 	if (unlikely(ret)) {
diff -ruN 4_9_337_orig/include/linux/mm.h 4_9_337_zram_entropy/include/linux/mm.h
--- 4_9_337_orig/include/linux/mm.h	2023-11-13 12:38:13.202325599 +0800
+++ 4_9_337_zram_entropy/include/linux/mm.h	2023-11-13 19:55:29.478712238 +0800
@@ -115,6 +115,9 @@
 extern unsigned long sysctl_user_reserve_kbytes;
 extern unsigned long sysctl_admin_reserve_kbytes;
 
+#ifdef CONFIG_ZRAM_ENTROPY
+extern unsigned long sysctl_zram_entropy_threshold;
+#endif
 extern int sysctl_overcommit_memory;
 extern int sysctl_overcommit_ratio;
 extern unsigned long sysctl_overcommit_kbytes;
diff -ruN 4_9_337_orig/kernel/sysctl.c 4_9_337_zram_entropy/kernel/sysctl.c
--- 4_9_337_orig/kernel/sysctl.c	2023-11-13 12:38:13.330329313 +0800
+++ 4_9_337_zram_entropy/kernel/sysctl.c	2023-11-13 19:55:44.927245219 +0800
@@ -1858,6 +1858,15 @@
 		.mode		= 0644,
 		.proc_handler	= proc_doulongvec_minmax,
 	},
+#ifdef CONFIG_ZRAM_ENTROPY
+	{
+		.procname	= "zram_entropy_threshold",
+		.data		= &sysctl_zram_entropy_threshold,
+		.maxlen		= sizeof(unsigned long),
+		.mode		= 0644,
+		.proc_handler	= proc_doulongvec_minmax,
+	},
+#endif
 #ifdef CONFIG_HAVE_ARCH_MMAP_RND_BITS
 	{
 		.procname	= "mmap_rnd_bits",
